{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d518a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be310ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b0b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5937f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing functions\n",
    "def remove_special_chars(text):\n",
    "    # Remove special characters and punctuation\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return clean_text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a286ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\ki_shari\\Downloads\\DFF.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a199183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>ORIGINAL_TEXT</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>incon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "      <td>0.723638</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID  LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0       1      1       4                 N               PC  B00008NG7N   \n",
       "1       2      1       4                 Y         Wireless  B00LH0Y3NM   \n",
       "2       3      1       3                 N             Baby  B000I5UZ1Q   \n",
       "3       4      1       4                 N  Office Products  B003822IRA   \n",
       "4       5      1       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                       PRODUCT_TITLE  \\\n",
       "0        Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "1  Note 3 Battery : Stalion Strength Replacement ...   \n",
       "2       Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "3  Casio MS-80B Standard Function Desktop Calculator   \n",
       "4  Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "               REVIEW_TITLE  \\\n",
       "0                    useful   \n",
       "1     New era for batteries   \n",
       "2  doesn't swing very well.   \n",
       "3          Great computing!   \n",
       "4     Only use twice a week   \n",
       "\n",
       "                                       ORIGINAL_TEXT  normalized_scores  \\\n",
       "0  When least you think so, this product will sav...           0.726538   \n",
       "1  Lithium batteries are something new introduced...           0.723638   \n",
       "2  I purchased this swing for my baby. She is 6 m...           0.483963   \n",
       "3  I was looking for an inexpensive desk calcolat...           0.726538   \n",
       "4  I only use it twice a week and the results are...           0.726538   \n",
       "\n",
       "    incon  \n",
       "0  Medium  \n",
       "1  Medium  \n",
       "2     Low  \n",
       "3  Medium  \n",
       "4  Medium  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a95362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        When least you think so, this product will sav...\n",
      "1        Lithium batteries are something new introduced...\n",
      "2        I purchased this swing for my baby. She is 6 m...\n",
      "3        I was looking for an inexpensive desk calcolat...\n",
      "4        I only use it twice a week and the results are...\n",
      "                               ...                        \n",
      "20995    I bought these for work.  I have high arches, ...\n",
      "20996    Crocs are one of only two brands of shoes that...\n",
      "20997    I love moccasins  This fit like it was custom ...\n",
      "20998    I wish these were a little more durable. I got...\n",
      "20999    I've been looking for a replacement for my bel...\n",
      "Name: ORIGINAL_TEXT, Length: 21000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['ORIGINAL_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f011b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"LABEL\"] == \"__label1__\", \"LABEL\"] = 1\n",
    "df.loc[df[\"LABEL\"] == \"__label2__\", \"LABEL\"] = 0\n",
    "df['LABEL']=pd.to_numeric(df['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10bf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing steps\n",
    "df['ORIGINAL_TEXT'] = df['ORIGINAL_TEXT'].apply(remove_special_chars)\n",
    "df['ORIGINAL_TEXT'] = df['ORIGINAL_TEXT'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455cef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into review text and labels\n",
    "reviews = df['ORIGINAL_TEXT'].values\n",
    "labels = df['LABEL'].values\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "#labels = tf.keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af89346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "20995    0\n",
      "20996    0\n",
      "20997    0\n",
      "20998    0\n",
      "20999    0\n",
      "Name: LABEL, Length: 21000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e251996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [least, think, product, save, day, keep, aroun...\n",
      "1        [lithium, batteri, someth, new, introduc, mark...\n",
      "2        [purchas, swing, babi, 6, month, pretti, much,...\n",
      "3        [look, inexpens, desk, calcolatur, work, every...\n",
      "4        [use, twice, week, result, great, use, teeth, ...\n",
      "                               ...                        \n",
      "20995    [bought, work, high, arch, use, arch, support,...\n",
      "20996    [croc, one, two, brand, shoe, foot, day, work,...\n",
      "20997    [love, moccasin, fit, like, custom, made, mebr...\n",
      "20998    [wish, littl, durabl, got, caught, bolt, cross...\n",
      "20999    [ive, look, replac, belov, kso, trek, own, two...\n",
      "Name: ORIGINAL_TEXT, Length: 21000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['ORIGINAL_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "029b194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_len = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Load GloVe word embeddings\n",
    "embedding_dim = 300  # Change this value based on the GloVe embedding you choose\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "glove_path = 'C:\\\\Users\\\\ki_shari\\\\Downloads\\\\glove.6B.300d.txt\\\\glove.6B.300d.txt'  # Provide the path to your GloVe file\n",
    "\n",
    "with open(glove_path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, *vector = line.split()\n",
    "        if word in word_index:\n",
    "            idx = word_index[word]\n",
    "            embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee63d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "263/263 [==============================] - 111s 419ms/step - loss: 0.6681 - accuracy: 0.5823 - val_loss: 0.6579 - val_accuracy: 0.6038 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 113s 430ms/step - loss: 0.5820 - accuracy: 0.6903 - val_loss: 0.6698 - val_accuracy: 0.6157 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 178s 677ms/step - loss: 0.4269 - accuracy: 0.8067 - val_loss: 0.8157 - val_accuracy: 0.5845 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 165s 626ms/step - loss: 0.2168 - accuracy: 0.9245 - val_loss: 1.1784 - val_accuracy: 0.5752 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 171s 649ms/step - loss: 0.0748 - accuracy: 0.9857 - val_loss: 1.0418 - val_accuracy: 0.5952 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 167s 634ms/step - loss: 0.0234 - accuracy: 0.9992 - val_loss: 1.1303 - val_accuracy: 0.5938 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 116s 440ms/step - loss: 0.0113 - accuracy: 0.9999 - val_loss: 1.2138 - val_accuracy: 0.5967 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 114s 433ms/step - loss: 0.0068 - accuracy: 0.9999 - val_loss: 1.2400 - val_accuracy: 0.5974 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 155s 590ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 1.2743 - val_accuracy: 0.5969 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 176s 668ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 1.3121 - val_accuracy: 0.5969 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 12s 92ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 173s 647ms/step - loss: 0.6678 - accuracy: 0.5879 - val_loss: 0.6518 - val_accuracy: 0.6131 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 167s 636ms/step - loss: 0.5755 - accuracy: 0.7000 - val_loss: 0.6683 - val_accuracy: 0.6133 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 173s 658ms/step - loss: 0.4106 - accuracy: 0.8220 - val_loss: 0.7629 - val_accuracy: 0.5983 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 173s 660ms/step - loss: 0.1925 - accuracy: 0.9364 - val_loss: 1.0617 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 161s 612ms/step - loss: 0.0584 - accuracy: 0.9906 - val_loss: 1.0958 - val_accuracy: 0.6045 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 167s 634ms/step - loss: 0.0174 - accuracy: 0.9996 - val_loss: 1.1879 - val_accuracy: 0.5902 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 166s 631ms/step - loss: 0.0089 - accuracy: 0.9999 - val_loss: 1.2553 - val_accuracy: 0.5962 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 164s 624ms/step - loss: 0.0057 - accuracy: 0.9999 - val_loss: 1.2887 - val_accuracy: 0.5979 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 171s 651ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 1.3185 - val_accuracy: 0.6007 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 166s 631ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 1.3509 - val_accuracy: 0.6026 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 12s 93ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 167s 622ms/step - loss: 0.6720 - accuracy: 0.5817 - val_loss: 0.6472 - val_accuracy: 0.6236 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 163s 620ms/step - loss: 0.5814 - accuracy: 0.6932 - val_loss: 0.6538 - val_accuracy: 0.6181 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 145s 551ms/step - loss: 0.4218 - accuracy: 0.8150 - val_loss: 0.7444 - val_accuracy: 0.5993 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 100s 381ms/step - loss: 0.2137 - accuracy: 0.9258 - val_loss: 0.9314 - val_accuracy: 0.6033 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 100s 379ms/step - loss: 0.0708 - accuracy: 0.9879 - val_loss: 1.0138 - val_accuracy: 0.6043 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 100s 381ms/step - loss: 0.0220 - accuracy: 0.9995 - val_loss: 1.1153 - val_accuracy: 0.6036 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 100s 380ms/step - loss: 0.0107 - accuracy: 0.9999 - val_loss: 1.1957 - val_accuracy: 0.6090 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 101s 383ms/step - loss: 0.0064 - accuracy: 0.9999 - val_loss: 1.2307 - val_accuracy: 0.6088 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 100s 380ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 1.2680 - val_accuracy: 0.6076 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 99s 378ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 1.3047 - val_accuracy: 0.6102 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 9s 67ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 102s 383ms/step - loss: 0.6698 - accuracy: 0.5836 - val_loss: 0.6527 - val_accuracy: 0.6169 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 99s 378ms/step - loss: 0.5802 - accuracy: 0.6944 - val_loss: 0.6576 - val_accuracy: 0.6198 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 101s 382ms/step - loss: 0.4131 - accuracy: 0.8233 - val_loss: 0.7544 - val_accuracy: 0.6021 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 100s 380ms/step - loss: 0.2010 - accuracy: 0.9295 - val_loss: 0.9889 - val_accuracy: 0.5867 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 99s 377ms/step - loss: 0.0646 - accuracy: 0.9880 - val_loss: 1.0882 - val_accuracy: 0.5971 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 99s 376ms/step - loss: 0.0181 - accuracy: 0.9996 - val_loss: 1.1841 - val_accuracy: 0.5967 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 99s 376ms/step - loss: 0.0087 - accuracy: 0.9999 - val_loss: 1.2613 - val_accuracy: 0.5976 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 99s 377ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2952 - val_accuracy: 0.5974 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 100s 379ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.5976 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 100s 380ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.3609 - val_accuracy: 0.5986 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 9s 66ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 108s 407ms/step - loss: 0.6687 - accuracy: 0.5913 - val_loss: 0.6586 - val_accuracy: 0.6014 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.5794 - accuracy: 0.6944 - val_loss: 0.6585 - val_accuracy: 0.6052 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 108s 410ms/step - loss: 0.4326 - accuracy: 0.8067 - val_loss: 0.7439 - val_accuracy: 0.5983 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 108s 412ms/step - loss: 0.2248 - accuracy: 0.9186 - val_loss: 0.9633 - val_accuracy: 0.5883 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 109s 413ms/step - loss: 0.0893 - accuracy: 0.9757 - val_loss: 1.2475 - val_accuracy: 0.5907 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 103s 390ms/step - loss: 0.0271 - accuracy: 0.9972 - val_loss: 1.2067 - val_accuracy: 0.5979 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 103s 391ms/step - loss: 0.0082 - accuracy: 0.9999 - val_loss: 1.2665 - val_accuracy: 0.6026 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 104s 396ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 1.3274 - val_accuracy: 0.6017 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 106s 405ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 1.3513 - val_accuracy: 0.6014 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 1.3756 - val_accuracy: 0.6010 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 9s 70ms/step\n",
      "Accuracy: 0.6019\n",
      "F1 Score: 0.6009\n",
      "Recall: 0.5994\n",
      "Precision: 0.6024\n",
      "AUC: 0.6019\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "    model.add(Conv1D(128, 5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Update the evaluation function\n",
    "def evaluate(y_true, y_pred):\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, f1, recall, precision, auc\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "accuracy_list, f1_list, recall_list, precision_list, auc_list = [], [], [], [], []\n",
    "\n",
    "for train_index, test_index in skf.split(padded_sequences, labels):\n",
    "    X_train, X_test = padded_sequences[train_index], padded_sequences[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    model = create_model()\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[reduce_lr])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    accuracy, f1, recall, precision, auc = evaluate(y_test, y_pred)\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    precision_list.append(precision)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Calculate average evaluation metrics\n",
    "avg_accuracy = np.mean(accuracy_list)\n",
    "avg_f1 = np.mean(f1_list)\n",
    "avg_recall = np.mean(recall_list)\n",
    "avg_precision = np.mean(precision_list)\n",
    "avg_auc = np.mean(auc_list)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.4f}\".format(avg_accuracy))\n",
    "print(\"F1 Score: {:.4f}\".format(avg_f1))\n",
    "print(\"Recall: {:.4f}\".format(avg_recall))\n",
    "print(\"Precision: {:.4f}\".format(avg_precision))\n",
    "print(\"AUC: {:.4f}\".format(avg_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f790c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate\n",
    "\n",
    "def create_cnn_model(vocab_size, embedding_dim, maxlen):\n",
    "    input_text = Input(shape=(maxlen,))\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, input_length=maxlen)(input_text)\n",
    "    conv1 = Conv1D(128, 3, activation='relu')(embedding_layer)\n",
    "    conv2 = Conv1D(128, 4, activation='relu')(embedding_layer)\n",
    "    conv3 = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
    "    \n",
    "    pooling1 = GlobalMaxPooling1D()(conv1)\n",
    "    pooling2 = GlobalMaxPooling1D()(conv2)\n",
    "    pooling3 = GlobalMaxPooling1D()(conv3)\n",
    "    \n",
    "    concatenated = Concatenate()([pooling1, pooling2, pooling3])\n",
    "    \n",
    "    dense1 = Dense(64, activation='relu')(concatenated)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(dropout1)\n",
    "    \n",
    "    model = Model(inputs=input_text, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4affdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "263/263 [==============================] - 44s 162ms/step - loss: 0.6664 - accuracy: 0.5879 - val_loss: 0.6392 - val_accuracy: 0.6421 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.6518 - val_accuracy: 0.6321 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 0.2755 - accuracy: 0.8931 - val_loss: 0.8493 - val_accuracy: 0.6210 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 42s 160ms/step - loss: 0.0670 - accuracy: 0.9819 - val_loss: 1.1510 - val_accuracy: 0.6100 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0133 - accuracy: 0.9982 - val_loss: 1.3898 - val_accuracy: 0.6214 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0054 - accuracy: 0.9999 - val_loss: 1.5487 - val_accuracy: 0.6302 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 1.6774 - val_accuracy: 0.6290 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7361 - val_accuracy: 0.6288 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 1.7868 - val_accuracy: 0.6274 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 1.8348 - val_accuracy: 0.6290 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 44s 162ms/step - loss: 0.6678 - accuracy: 0.5850 - val_loss: 0.6446 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.5381 - accuracy: 0.7366 - val_loss: 0.6617 - val_accuracy: 0.6312 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.2746 - accuracy: 0.8943 - val_loss: 0.7981 - val_accuracy: 0.6129 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0685 - accuracy: 0.9804 - val_loss: 1.1566 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0162 - accuracy: 0.9973 - val_loss: 1.4024 - val_accuracy: 0.6181 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 1.5425 - val_accuracy: 0.6224 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 1.7121 - val_accuracy: 0.6188 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 1.7986 - val_accuracy: 0.6181 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 1.8659 - val_accuracy: 0.6176 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.9206 - val_accuracy: 0.6179 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 44s 162ms/step - loss: 0.6702 - accuracy: 0.5781 - val_loss: 0.6434 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.5459 - accuracy: 0.7309 - val_loss: 0.6479 - val_accuracy: 0.6488 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.2668 - accuracy: 0.8976 - val_loss: 0.7796 - val_accuracy: 0.6381 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0545 - accuracy: 0.9862 - val_loss: 1.0871 - val_accuracy: 0.6245 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 1.2396 - val_accuracy: 0.6407 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 1.4035 - val_accuracy: 0.6369 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 1.4766 - val_accuracy: 0.6412 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 1.5376 - val_accuracy: 0.6417 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 1.5969 - val_accuracy: 0.6402 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.6395 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 44s 162ms/step - loss: 0.6671 - accuracy: 0.5824 - val_loss: 0.6524 - val_accuracy: 0.6167 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.5391 - accuracy: 0.7388 - val_loss: 0.6493 - val_accuracy: 0.6426 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 42s 162ms/step - loss: 0.2666 - accuracy: 0.9001 - val_loss: 0.8288 - val_accuracy: 0.6193 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0609 - accuracy: 0.9839 - val_loss: 1.1044 - val_accuracy: 0.6188 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 1.4247 - val_accuracy: 0.6233 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 1.6342 - val_accuracy: 0.6312 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 1.7260 - val_accuracy: 0.6271 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 1.8780 - val_accuracy: 0.6293 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9341 - val_accuracy: 0.6276 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 1.9764 - val_accuracy: 0.6295 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 44s 162ms/step - loss: 0.6656 - accuracy: 0.5874 - val_loss: 0.6379 - val_accuracy: 0.6352 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.5328 - accuracy: 0.7375 - val_loss: 0.6473 - val_accuracy: 0.6376 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.2486 - accuracy: 0.9066 - val_loss: 0.8749 - val_accuracy: 0.6348 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 43s 163ms/step - loss: 0.0554 - accuracy: 0.9852 - val_loss: 1.1238 - val_accuracy: 0.6150 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 43s 165ms/step - loss: 0.0127 - accuracy: 0.9982 - val_loss: 1.3440 - val_accuracy: 0.6336 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 1.5318 - val_accuracy: 0.6338 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 1.6519 - val_accuracy: 0.6343 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 1.7001 - val_accuracy: 0.6331 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 42s 161ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.6343 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "263/263 [==============================] - 43s 162ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8211 - val_accuracy: 0.6338 - lr: 2.5000e-04\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "Accuracy: 0.6300\n",
      "F1 Score: 0.6382\n",
      "Recall: 0.6528\n",
      "Precision: 0.6243\n",
      "AUC: 0.6300\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "# Update the evaluation function\n",
    "def evaluate(y_true, y_pred):\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    return accuracy, f1, recall, precision, auc\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "accuracy_list, f1_list, recall_list, precision_list, auc_list = [], [], [], [], []\n",
    "\n",
    "for train_index, test_index in skf.split(padded_sequences, labels):\n",
    "    X_train, X_test = padded_sequences[train_index], padded_sequences[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    model = create_cnn_model(num_words, embedding_dim, max_len)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64, callbacks=[reduce_lr])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    accuracy, f1, recall, precision, auc = evaluate(y_test, y_pred)\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    recall_list.append(recall)\n",
    "    precision_list.append(precision)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "# Calculate average evaluation metrics\n",
    "avg_accuracy = np.mean(accuracy_list)\n",
    "avg_f1 = np.mean(f1_list)\n",
    "avg_recall = np.mean(recall_list)\n",
    "avg_precision = np.mean(precision_list)\n",
    "avg_auc = np.mean(auc_list)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.4f}\".format(avg_accuracy))\n",
    "print(\"F1 Score: {:.4f}\".format(avg_f1))\n",
    "print(\"Recall: {:.4f}\".format(avg_recall))\n",
    "print(\"Precision: {:.4f}\".format(avg_precision))\n",
    "print(\"AUC: {:.4f}\".format(avg_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66d6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
