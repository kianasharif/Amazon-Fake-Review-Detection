{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d518a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be310ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25b0b111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ki_shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5937f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing functions\n",
    "def remove_special_chars(text):\n",
    "    # Remove special characters and punctuation\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return clean_text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
    "\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a286ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\ki_shari\\Downloads\\DFF.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a199183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VERIFIED_PURCHASE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TITLE</th>\n",
       "      <th>REVIEW_TITLE</th>\n",
       "      <th>ORIGINAL_TEXT</th>\n",
       "      <th>normalized_scores</th>\n",
       "      <th>incon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>B00008NG7N</td>\n",
       "      <td>Targus PAUK10U Ultra Mini USB Keypad, Black</td>\n",
       "      <td>useful</td>\n",
       "      <td>When least you think so, this product will sav...</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>Wireless</td>\n",
       "      <td>B00LH0Y3NM</td>\n",
       "      <td>Note 3 Battery : Stalion Strength Replacement ...</td>\n",
       "      <td>New era for batteries</td>\n",
       "      <td>Lithium batteries are something new introduced...</td>\n",
       "      <td>0.723638</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Baby</td>\n",
       "      <td>B000I5UZ1Q</td>\n",
       "      <td>Fisher-Price Papasan Cradle Swing, Starlight</td>\n",
       "      <td>doesn't swing very well.</td>\n",
       "      <td>I purchased this swing for my baby. She is 6 m...</td>\n",
       "      <td>0.483963</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>B003822IRA</td>\n",
       "      <td>Casio MS-80B Standard Function Desktop Calculator</td>\n",
       "      <td>Great computing!</td>\n",
       "      <td>I was looking for an inexpensive desk calcolat...</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>B00PWSAXAM</td>\n",
       "      <td>Shine Whitening - Zero Peroxide Teeth Whitenin...</td>\n",
       "      <td>Only use twice a week</td>\n",
       "      <td>I only use it twice a week and the results are...</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID  LABEL  RATING VERIFIED_PURCHASE PRODUCT_CATEGORY  PRODUCT_ID  \\\n",
       "0       1      1       4                 N               PC  B00008NG7N   \n",
       "1       2      1       4                 Y         Wireless  B00LH0Y3NM   \n",
       "2       3      1       3                 N             Baby  B000I5UZ1Q   \n",
       "3       4      1       4                 N  Office Products  B003822IRA   \n",
       "4       5      1       4                 N           Beauty  B00PWSAXAM   \n",
       "\n",
       "                                       PRODUCT_TITLE  \\\n",
       "0        Targus PAUK10U Ultra Mini USB Keypad, Black   \n",
       "1  Note 3 Battery : Stalion Strength Replacement ...   \n",
       "2       Fisher-Price Papasan Cradle Swing, Starlight   \n",
       "3  Casio MS-80B Standard Function Desktop Calculator   \n",
       "4  Shine Whitening - Zero Peroxide Teeth Whitenin...   \n",
       "\n",
       "               REVIEW_TITLE  \\\n",
       "0                    useful   \n",
       "1     New era for batteries   \n",
       "2  doesn't swing very well.   \n",
       "3          Great computing!   \n",
       "4     Only use twice a week   \n",
       "\n",
       "                                       ORIGINAL_TEXT  normalized_scores  \\\n",
       "0  When least you think so, this product will sav...           0.726538   \n",
       "1  Lithium batteries are something new introduced...           0.723638   \n",
       "2  I purchased this swing for my baby. She is 6 m...           0.483963   \n",
       "3  I was looking for an inexpensive desk calcolat...           0.726538   \n",
       "4  I only use it twice a week and the results are...           0.726538   \n",
       "\n",
       "    incon  \n",
       "0  Medium  \n",
       "1  Medium  \n",
       "2     Low  \n",
       "3  Medium  \n",
       "4  Medium  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76a95362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        When least you think so, this product will sav...\n",
      "1        Lithium batteries are something new introduced...\n",
      "2        I purchased this swing for my baby. She is 6 m...\n",
      "3        I was looking for an inexpensive desk calcolat...\n",
      "4        I only use it twice a week and the results are...\n",
      "                               ...                        \n",
      "20995    I bought these for work.  I have high arches, ...\n",
      "20996    Crocs are one of only two brands of shoes that...\n",
      "20997    I love moccasins  This fit like it was custom ...\n",
      "20998    I wish these were a little more durable. I got...\n",
      "20999    I've been looking for a replacement for my bel...\n",
      "Name: ORIGINAL_TEXT, Length: 21000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['ORIGINAL_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f011b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"LABEL\"] == \"__label1__\", \"LABEL\"] = 1\n",
    "df.loc[df[\"LABEL\"] == \"__label2__\", \"LABEL\"] = 0\n",
    "df['LABEL']=pd.to_numeric(df['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b10bf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing steps\n",
    "df['ORIGINAL_TEXT'] = df['ORIGINAL_TEXT'].apply(remove_special_chars)\n",
    "df['ORIGINAL_TEXT'] = df['ORIGINAL_TEXT'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7320301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAGdCAYAAAAbudkLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAp2ElEQVR4nO3df1RU553H8c+IOAKFicAC0mJqtpRqsPmhCWKywawCRgnJ8ZyYDSnRxipdDZagsTEmG0wiNDZRz5HUqHWV+iP2nE3cdreUgmcjqQcVxZBGw5puYow2Im6CgwYyjHD3jxzudsQYSWcy8vB+ncM53me+95nnjjxzPz5zr+OwLMsSAACAgQYFewAAAACBQtABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABhrcLAHEEzd3d366KOPFBkZKYfDEezhAACAK2BZls6dO6fExEQNGnT5NZsBHXQ++ugjJSUlBXsYAADgKzhx4oS+9a1vXbZmQAedyMhISZ+/UFFRUX7t2+v1qrq6WllZWQoNDfVr3wC+HHMQCL5AzcO2tjYlJSXZ5/HLGdBBp+fjqqioqIAEnfDwcEVFRfEmCwQBcxAIvkDPwyu57ISLkQEAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMNTjYAzBdaskf5On68q+Rv1p88LNpwR4CAAB+w4oOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMbqc9B54403dPfddysxMVEOh0P//u//7vO4ZVkqKSlRYmKiwsLCNHHiRB05csSnxuPxqLCwULGxsYqIiFBubq5OnjzpU9Pa2qr8/Hy5XC65XC7l5+fr7NmzPjUffvih7r77bkVERCg2NlYLFixQZ2dnXw8JAAAYqs9B59NPP9UNN9yg8vLySz6+YsUKrVy5UuXl5Tpw4IASEhKUmZmpc+fO2TVFRUXauXOnduzYoT179uj8+fPKyclRV1eXXZOXl6fGxkZVVVWpqqpKjY2Nys/Ptx/v6urStGnT9Omnn2rPnj3asWOHXn31VS1cuLCvhwQAAAw1uK873HXXXbrrrrsu+ZhlWVq9erWWLl2q6dOnS5IqKioUHx+v7du3q6CgQG63Wxs3btSWLVs0efJkSdLWrVuVlJSkXbt2KTs7W01NTaqqqtK+ffuUlpYmSdqwYYPS09N19OhRpaSkqLq6Wu+8845OnDihxMRESdKLL76oWbNmafny5YqKivpKLwgAADBHn4PO5Rw7dkzNzc3Kysqy25xOpzIyMlRXV6eCggI1NDTI6/X61CQmJio1NVV1dXXKzs7W3r175XK57JAjSePHj5fL5VJdXZ1SUlK0d+9epaam2iFHkrKzs+XxeNTQ0KA777yz1/g8Ho88Ho+93dbWJknyer3yer3+fCns/pyDLL/2G2j+fh2AYOn5XeZ3GgieQM3DvvTn16DT3NwsSYqPj/dpj4+P1/Hjx+2aIUOGaNiwYb1qevZvbm5WXFxcr/7j4uJ8ai5+nmHDhmnIkCF2zcXKysq0bNmyXu3V1dUKDw+/kkPss2fHdQek30CprKwM9hAAv6qpqQn2EIABz9/zsL29/Ypr/Rp0ejgcDp9ty7J6tV3s4ppL1X+Vmr+2ZMkSFRcX29ttbW1KSkpSVlaW3z/q8nq9qqmp0VMHB8nTffljv5ocLskO9hAAv+iZg5mZmQoNDQ32cIABKVDzsOcTmSvh16CTkJAg6fPVluHDh9vtLS0t9upLQkKCOjs71dra6rOq09LSogkTJtg1p0+f7tX/mTNnfPrZv3+/z+Otra3yer29Vnp6OJ1OOZ3OXu2hoaEBeyP0dDvk6eo/QYcTAkwTyPkN4Mr4ex72pS+//j86I0eOVEJCgs8SVWdnp2pra+0QM3bsWIWGhvrUnDp1SocPH7Zr0tPT5Xa7VV9fb9fs379fbrfbp+bw4cM6deqUXVNdXS2n06mxY8f687AAAEA/1ecVnfPnz+t//ud/7O1jx46psbFR0dHRGjFihIqKilRaWqrk5GQlJyertLRU4eHhysvLkyS5XC7Nnj1bCxcuVExMjKKjo7Vo0SKNGTPGvgtr1KhRmjJliubMmaN169ZJkubOnaucnBylpKRIkrKysjR69Gjl5+fr5z//uT755BMtWrRIc+bM4Y4rAAAg6SsEnYMHD/rc0dRzzcvMmTO1efNmLV68WB0dHZo3b55aW1uVlpam6upqRUZG2vusWrVKgwcP1owZM9TR0aFJkyZp8+bNCgkJsWu2bdumBQsW2Hdn5ebm+vzfPSEhIfrd736nefPm6bbbblNYWJjy8vL0wgsv9P1VAAAARnJYltW/7n/2o7a2NrlcLrnd7oBcjFxZWanF9SH96hqdD342LdhDAPyiZw5OnTqVa3SAIAnUPOzL+ZvvugIAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjOX3oHPhwgU9+eSTGjlypMLCwnTdddfpmWeeUXd3t11jWZZKSkqUmJiosLAwTZw4UUeOHPHpx+PxqLCwULGxsYqIiFBubq5OnjzpU9Pa2qr8/Hy5XC65XC7l5+fr7Nmz/j4kAADQT/k96Dz//PN6+eWXVV5erqamJq1YsUI///nPtWbNGrtmxYoVWrlypcrLy3XgwAElJCQoMzNT586ds2uKioq0c+dO7dixQ3v27NH58+eVk5Ojrq4uuyYvL0+NjY2qqqpSVVWVGhsblZ+f7+9DAgAA/dRgf3e4d+9e3XPPPZo2bZok6dvf/rZeeeUVHTx4UNLnqzmrV6/W0qVLNX36dElSRUWF4uPjtX37dhUUFMjtdmvjxo3asmWLJk+eLEnaunWrkpKStGvXLmVnZ6upqUlVVVXat2+f0tLSJEkbNmxQenq6jh49qpSUFH8fGgAA6Gf8HnRuv/12vfzyy3r33Xf13e9+V2+99Zb27Nmj1atXS5KOHTum5uZmZWVl2fs4nU5lZGSorq5OBQUFamhokNfr9alJTExUamqq6urqlJ2drb1798rlctkhR5LGjx8vl8ulurq6SwYdj8cjj8djb7e1tUmSvF6vvF6vX1+Hnv6cgyy/9hto/n4dgGDp+V3mdxoInkDNw7705/eg89Of/lRut1vf+973FBISoq6uLi1fvlwPPPCAJKm5uVmSFB8f77NffHy8jh8/btcMGTJEw4YN61XTs39zc7Pi4uJ6PX9cXJxdc7GysjItW7asV3t1dbXCw8P7eKRX5tlx3V9edBWprKwM9hAAv6qpqQn2EIABz9/zsL29/Ypr/R50fv3rX2vr1q3avn27rr/+ejU2NqqoqEiJiYmaOXOmXedwOHz2syyrV9vFLq65VP3l+lmyZImKi4vt7ba2NiUlJSkrK0tRUVFXdHxXyuv1qqamRk8dHCRP9+WP62pyuCQ72EMA/KJnDmZmZio0NDTYwwEGpEDNw55PZK6E34POY489pscff1z/9E//JEkaM2aMjh8/rrKyMs2cOVMJCQmSPl+RGT58uL1fS0uLvcqTkJCgzs5Otba2+qzqtLS0aMKECXbN6dOnez3/mTNneq0W9XA6nXI6nb3aQ0NDA/ZG6Ol2yNPVf4IOJwSYJpDzG8CV8fc87Etffr/rqr29XYMG+XYbEhJi314+cuRIJSQk+CxjdXZ2qra21g4xY8eOVWhoqE/NqVOndPjwYbsmPT1dbrdb9fX1ds3+/fvldrvtGgAAMLD5fUXn7rvv1vLlyzVixAhdf/31evPNN7Vy5Uo9/PDDkj7/uKmoqEilpaVKTk5WcnKySktLFR4erry8PEmSy+XS7NmztXDhQsXExCg6OlqLFi3SmDFj7LuwRo0apSlTpmjOnDlat26dJGnu3LnKycnhjisAACApAEFnzZo1euqppzRv3jy1tLQoMTFRBQUF+pd/+Re7ZvHixero6NC8efPU2tqqtLQ0VVdXKzIy0q5ZtWqVBg8erBkzZqijo0OTJk3S5s2bFRISYtds27ZNCxYssO/Oys3NVXl5ub8PCQAA9FMOy7L61/3PftTW1iaXyyW32x2Qi5ErKyu1uD6kX12j88HPpgV7CIBf9MzBqVOnco0OECSBmod9OX/zXVcAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLECEnT+8pe/6Ac/+IFiYmIUHh6uG2+8UQ0NDfbjlmWppKREiYmJCgsL08SJE3XkyBGfPjwejwoLCxUbG6uIiAjl5ubq5MmTPjWtra3Kz8+Xy+WSy+VSfn6+zp49G4hDAgAA/ZDfg05ra6tuu+02hYaG6ve//73eeecdvfjii7rmmmvsmhUrVmjlypUqLy/XgQMHlJCQoMzMTJ07d86uKSoq0s6dO7Vjxw7t2bNH58+fV05Ojrq6uuyavLw8NTY2qqqqSlVVVWpsbFR+fr6/DwkAAPRTg/3d4fPPP6+kpCRt2rTJbvv2t79t/9myLK1evVpLly7V9OnTJUkVFRWKj4/X9u3bVVBQILfbrY0bN2rLli2aPHmyJGnr1q1KSkrSrl27lJ2draamJlVVVWnfvn1KS0uTJG3YsEHp6ek6evSoUlJS/H1oAACgn/F70Pntb3+r7Oxs3XfffaqtrdU3v/lNzZs3T3PmzJEkHTt2TM3NzcrKyrL3cTqdysjIUF1dnQoKCtTQ0CCv1+tTk5iYqNTUVNXV1Sk7O1t79+6Vy+WyQ44kjR8/Xi6XS3V1dZcMOh6PRx6Px95ua2uTJHm9Xnm9Xr++Dj39OQdZfu030Pz9OgDB0vO7zO80EDyBmod96c/vQef999/X2rVrVVxcrCeeeEL19fVasGCBnE6nHnroITU3N0uS4uPjffaLj4/X8ePHJUnNzc0aMmSIhg0b1qumZ//m5mbFxcX1ev64uDi75mJlZWVatmxZr/bq6mqFh4f3/WCvwLPjugPSb6BUVlYGewiAX9XU1AR7CMCA5+952N7efsW1fg863d3dGjdunEpLSyVJN910k44cOaK1a9fqoYcesuscDofPfpZl9Wq72MU1l6q/XD9LlixRcXGxvd3W1qakpCRlZWUpKirqyw+uD7xer2pqavTUwUHydF/+uK4mh0uygz0EwC965mBmZqZCQ0ODPRxgQArUPOz5ROZK+D3oDB8+XKNHj/ZpGzVqlF599VVJUkJCgqTPV2SGDx9u17S0tNirPAkJCers7FRra6vPqk5LS4smTJhg15w+fbrX8585c6bXalEPp9Mpp9PZqz00NDRgb4Seboc8Xf0n6HBCgGkCOb8BXBl/z8O+9OX3u65uu+02HT161Kft3Xff1bXXXitJGjlypBISEnyWsTo7O1VbW2uHmLFjxyo0NNSn5tSpUzp8+LBdk56eLrfbrfr6ertm//79crvddg0AABjY/L6i8+ijj2rChAkqLS3VjBkzVF9fr/Xr12v9+vWSPv+4qaioSKWlpUpOTlZycrJKS0sVHh6uvLw8SZLL5dLs2bO1cOFCxcTEKDo6WosWLdKYMWPsu7BGjRqlKVOmaM6cOVq3bp0kae7cucrJyeGOKwAAICkAQeeWW27Rzp07tWTJEj3zzDMaOXKkVq9erQcffNCuWbx4sTo6OjRv3jy1trYqLS1N1dXVioyMtGtWrVqlwYMHa8aMGero6NCkSZO0efNmhYSE2DXbtm3TggUL7LuzcnNzVV5e7u9DAgAA/ZTDsqz+df+zH7W1tcnlcsntdgfkYuTKykotrg/pV9fofPCzacEeAuAXPXNw6tSpXKMDBEmg5mFfzt981xUAADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAw1uBgDwAAAim15A/ydDmCPYwr9sHPpgV7CIBRWNEBAADGYkUHAIB+4NuP/y7YQ+gzZ4ilFbcGdwys6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgrIAHnbKyMjkcDhUVFdltlmWppKREiYmJCgsL08SJE3XkyBGf/TwejwoLCxUbG6uIiAjl5ubq5MmTPjWtra3Kz8+Xy+WSy+VSfn6+zp49G+hDAgAA/URAg86BAwe0fv16ff/73/dpX7FihVauXKny8nIdOHBACQkJyszM1Llz5+yaoqIi7dy5Uzt27NCePXt0/vx55eTkqKury67Jy8tTY2OjqqqqVFVVpcbGRuXn5wfykAAAQD8SsKBz/vx5Pfjgg9qwYYOGDRtmt1uWpdWrV2vp0qWaPn26UlNTVVFRofb2dm3fvl2S5Ha7tXHjRr344ouaPHmybrrpJm3dulVvv/22du3aJUlqampSVVWVfvnLXyo9PV3p6enasGGD/vM//1NHjx4N1GEBAIB+ZHCgOp4/f76mTZumyZMn67nnnrPbjx07pubmZmVlZdltTqdTGRkZqqurU0FBgRoaGuT1en1qEhMTlZqaqrq6OmVnZ2vv3r1yuVxKS0uza8aPHy+Xy6W6ujqlpKT0GpPH45HH47G329raJEler1der9evx9/Tn3OQ5dd+A83frwMQLMxBmMYZ0r9+l6X/n3+BOsdeiYAEnR07dujQoUM6cOBAr8eam5slSfHx8T7t8fHxOn78uF0zZMgQn5Wgnpqe/ZubmxUXF9er/7i4OLvmYmVlZVq2bFmv9urqaoWHh1/BkfXds+O6A9JvoFRWVgZ7CIBfMQdhihW3BnsEX11NTY1f+2tvb7/iWr8HnRMnTugnP/mJqqurNXTo0C+sczgcPtuWZfVqu9jFNZeqv1w/S5YsUXFxsb3d1tampKQkZWVlKSoq6rLP3Vder1c1NTV66uAgebovf1xXk8Ml2cEeAuAXzEGYJrXkD8EeQp85B1l6dly3MjMzFRoa6rd+ez6RuRJ+DzoNDQ1qaWnR2LFj7bauri698cYbKi8vt6+faW5u1vDhw+2alpYWe5UnISFBnZ2dam1t9VnVaWlp0YQJE+ya06dP93r+M2fO9Fot6uF0OuV0Onu1h4aG+vUv4K95uh3ydPWfN9lAvQ5AsDAHYYr+9Ht8MX+fZ/vSl98vRp40aZLefvttNTY22j/jxo3Tgw8+qMbGRl133XVKSEjwWcbq7OxUbW2tHWLGjh2r0NBQn5pTp07p8OHDdk16errcbrfq6+vtmv3798vtdts1AABgYPP7ik5kZKRSU1N92iIiIhQTE2O3FxUVqbS0VMnJyUpOTlZpaanCw8OVl5cnSXK5XJo9e7YWLlyomJgYRUdHa9GiRRozZowmT54sSRo1apSmTJmiOXPmaN26dZKkuXPnKicn55IXIgMAgIEnYHddXc7ixYvV0dGhefPmqbW1VWlpaaqurlZkZKRds2rVKg0ePFgzZsxQR0eHJk2apM2bNyskJMSu2bZtmxYsWGDfnZWbm6vy8vKv/XgAAMDV6WsJOrt37/bZdjgcKikpUUlJyRfuM3ToUK1Zs0Zr1qz5wpro6Ght3brVT6MEAACm4buuAACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABj+T3olJWV6ZZbblFkZKTi4uJ077336ujRoz41lmWppKREiYmJCgsL08SJE3XkyBGfGo/Ho8LCQsXGxioiIkK5ubk6efKkT01ra6vy8/PlcrnkcrmUn5+vs2fP+vuQAABAP+X3oFNbW6v58+dr3759qqmp0YULF5SVlaVPP/3UrlmxYoVWrlyp8vJyHThwQAkJCcrMzNS5c+fsmqKiIu3cuVM7duzQnj17dP78eeXk5Kirq8uuycvLU2Njo6qqqlRVVaXGxkbl5+f7+5AAAEA/NdjfHVZVVflsb9q0SXFxcWpoaNAdd9why7K0evVqLV26VNOnT5ckVVRUKD4+Xtu3b1dBQYHcbrc2btyoLVu2aPLkyZKkrVu3KikpSbt27VJ2draamppUVVWlffv2KS0tTZK0YcMGpaen6+jRo0pJSfH3oQEAgH7G70HnYm63W5IUHR0tSTp27Jiam5uVlZVl1zidTmVkZKiurk4FBQVqaGiQ1+v1qUlMTFRqaqrq6uqUnZ2tvXv3yuVy2SFHksaPHy+Xy6W6urpLBh2PxyOPx2Nvt7W1SZK8Xq+8Xq9fj7unP+cgy6/9Bpq/XwcgWJiDMI0zpH/9Lkv/P/8CdY69EgENOpZlqbi4WLfffrtSU1MlSc3NzZKk+Ph4n9r4+HgdP37crhkyZIiGDRvWq6Zn/+bmZsXFxfV6zri4OLvmYmVlZVq2bFmv9urqaoWHh/fx6K7Ms+O6A9JvoFRWVgZ7CIBfMQdhihW3BnsEX11NTY1f+2tvb7/i2oAGnUceeUR/+tOftGfPnl6PORwOn23Lsnq1XezimkvVX66fJUuWqLi42N5ua2tTUlKSsrKyFBUVddnn7iuv16uamho9dXCQPN2XP66ryeGS7GAPAfAL5iBMk1ryh2APoc+cgyw9O65bmZmZCg0N9Vu/PZ/IXImABZ3CwkL99re/1RtvvKFvfetbdntCQoKkz1dkhg8fbre3tLTYqzwJCQnq7OxUa2urz6pOS0uLJkyYYNecPn261/OeOXOm12pRD6fTKafT2as9NDTUr38Bf83T7ZCnq/+8yQbqdQCChTkIU/Sn3+OL+fs825e+/H7XlWVZeuSRR/Taa6/pv/7rvzRy5Eifx0eOHKmEhASfZazOzk7V1tbaIWbs2LEKDQ31qTl16pQOHz5s16Snp8vtdqu+vt6u2b9/v9xut10DAAAGNr+v6MyfP1/bt2/Xb37zG0VGRtrXy7hcLoWFhcnhcKioqEilpaVKTk5WcnKySktLFR4erry8PLt29uzZWrhwoWJiYhQdHa1FixZpzJgx9l1Yo0aN0pQpUzRnzhytW7dOkjR37lzl5ORwxxUAAJAUgKCzdu1aSdLEiRN92jdt2qRZs2ZJkhYvXqyOjg7NmzdPra2tSktLU3V1tSIjI+36VatWafDgwZoxY4Y6Ojo0adIkbd68WSEhIXbNtm3btGDBAvvurNzcXJWXl/v7kAAAQD/l96BjWV9++5vD4VBJSYlKSkq+sGbo0KFas2aN1qxZ84U10dHR2rp161cZJgAAGAD4risAAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFj9Puj84he/0MiRIzV06FCNHTtWf/zjH4M9JAAAcJXo10Hn17/+tYqKirR06VK9+eab+od/+Afddddd+vDDD4M9NAAAcBXo10Fn5cqVmj17tn70ox9p1KhRWr16tZKSkrR27dpgDw0AAFwFBgd7AF9VZ2enGhoa9Pjjj/u0Z2Vlqa6u7pL7eDweeTwee9vtdkuSPvnkE3m9Xr+Oz+v1qr29XYO9g9TV7fBr34H08ccfB3sIgF8wB2GawRc+DfYQ+mxwt6X29m59/PHHCg0N9Vu/586dkyRZlvXlY/Dbs37N/vd//1ddXV2Kj4/3aY+Pj1dzc/Ml9ykrK9OyZct6tY8cOTIgY+yPYl8M9giAgY05CNPkBbDvc+fOyeVyXbam3wadHg6H77/ULMvq1dZjyZIlKi4utre7u7v1ySefKCYm5gv3+ara2tqUlJSkEydOKCoqyq99A/hyzEEg+AI1Dy3L0rlz55SYmPiltf026MTGxiokJKTX6k1LS0uvVZ4eTqdTTqfTp+2aa64J1BAlSVFRUbzJAkHEHASCLxDz8MtWcnr024uRhwwZorFjx6qmpsanvaamRhMmTAjSqAAAwNWk367oSFJxcbHy8/M1btw4paena/369frwww/14x//ONhDAwAAV4F+HXTuv/9+ffzxx3rmmWd06tQppaamqrKyUtdee22whyan06mnn36610dlAL4ezEEg+K6GeeiwruTeLAAAgH6o316jAwAA8GUIOgAAwFgEHQAAYCyCjp/t3r1bDodDZ8+elSRt3rw54P9XDwAAwfZVznezZs3SvffeG5Dx9BhwQWfWrFlyOByXvAV93rx5cjgcmjVrlt+e7/7779e7777rt/6AgezreFME0NsXzb2//sf91Xq+G3BBR5KSkpK0Y8cOdXR02G2fffaZXnnlFY0YMcKvzxUWFqa4uDi/9gkAwNXmaj3fDcigc/PNN2vEiBF67bXX7LbXXntNSUlJuummm+w2y7K0YsUKXXfddQoLC9MNN9ygf/u3f/Ppq7KyUt/97ncVFhamO++8Ux988IHP4xcv5V0qFRcVFWnixIn29sSJE1VYWKiioiINGzZM8fHxWr9+vT799FP98Ic/VGRkpP7+7/9ev//97//m1wIwRW1trW699VY5nU4NHz5cjz/+uC5cuCBJ+o//+A9dc8016u7uliQ1NjbK4XDoscces/cvKCjQAw88EJSxAya41EdXzz33nOLi4hQZGakf/ehHevzxx3XjjTf22veFF17Q8OHDFRMTo/nz58vr9fptXAMy6EjSD3/4Q23atMne/td//Vc9/PDDPjVPPvmkNm3apLVr1+rIkSN69NFH9YMf/EC1tbWSpBMnTmj69OmaOnWqGhsb7b9Ef6ioqFBsbKzq6+tVWFiof/7nf9Z9992nCRMm6NChQ8rOzlZ+fr7a29v98nxAf/aXv/xFU6dO1S233KK33npLa9eu1caNG/Xcc89Jku644w6dO3dOb775pqTPQ1FsbKw9l6XPl+AzMjKCMn7ARNu2bdPy5cv1/PPPq6GhQSNGjNDatWt71b3++ut677339Prrr6uiokKbN2/W5s2b/TcQa4CZOXOmdc8991hnzpyxnE6ndezYMeuDDz6whg4dap05c8a65557rJkzZ1rnz5+3hg4datXV1fnsP3v2bOuBBx6wLMuylixZYo0aNcrq7u62H//pT39qSbJaW1sty7KsTZs2WS6Xq9fz/7Wf/OQnVkZGhr2dkZFh3X777fb2hQsXrIiICCs/P99uO3XqlCXJ2rt379/4igD9x6Xmj2VZ1hNPPGGlpKT4zMWXXnrJ+sY3vmF1dXVZlmVZN998s/XCCy9YlmVZ9957r7V8+XJryJAhVltbmz2fmpqavpbjAPqbmTNnWiEhIVZERITPz9ChQ+1z3sXnu7S0NGv+/Pk+/dx2223WDTfc4NPvtddea124cMFuu++++6z777/fb2MfsCs6sbGxmjZtmioqKrRp0yZNmzZNsbGx9uPvvPOOPvvsM2VmZuob3/iG/fOrX/1K7733niSpqalJ48ePl8PhsPdLT0/3y/i+//3v238OCQlRTEyMxowZY7f1fEN7S0uLX54P6M+ampqUnp7uMxdvu+02nT9/XidPnpT0+UfCu3fvlmVZ+uMf/6h77rlHqamp2rNnj15//XXFx8fre9/7XrAOAbjq3XnnnWpsbPT5+eUvf/mF9UePHtWtt97q03bxtiRdf/31CgkJsbeHDx/u13Nbv/6uq7/Vww8/rEceeUSS9NJLL/k81vNZ/u9+9zt985vf9Hms5zs7rK/w7RmDBg3qtd+lPosMDQ312XY4HD5tPW/oPeMEBjLLsnxCTk+b9P9zZeLEidq4caPeeustDRo0SKNHj1ZGRoZqa2vV2trKx1bAl4iIiNB3vvMdn7aef0h8kS+al3/tUuc7f57bBuyKjiRNmTJFnZ2d6uzsVHZ2ts9jo0ePltPp1IcffqjvfOc7Pj9JSUl2zb59+3z2u3j7Yn/3d3+nU6dO+bQ1Njb+7QcDDGCjR49WXV2dz5toXV2dIiMj7X+o9Fyns3r1amVkZMjhcCgjI0O7d+/m+hwgAFJSUlRfX+/TdvDgwa99HAM66ISEhKipqUlNTU0+y2aSFBkZqUWLFunRRx9VRUWF3nvvPb355pt66aWXVFFRIUn68Y9/rPfee0/FxcU6evSotm/f/qUXUP3jP/6jDh48qF/96lf685//rKefflqHDx8O1CECxnG73b2Wz+fOnasTJ06osLBQ//3f/63f/OY3evrpp1VcXKxBgz5/m3O5XLrxxhu1detW+y7HO+64Q4cOHdK7777rc+cjgL9dYWGhNm7cqIqKCv35z3/Wc889pz/96U+9VnkCbUB/dCVJUVFRX/jYs88+q7i4OJWVlen999/XNddco5tvvllPPPGEJGnEiBF69dVX9eijj+oXv/iFbr31VpWWlva6e+uvZWdn66mnntLixYv12Wef6eGHH9ZDDz2kt99+2+/HBpho9+7dPv8NhCTNnDlTlZWVeuyxx3TDDTcoOjpas2fP1pNPPulTd+edd+rQoUN2qBk2bJhGjx6tjz76SKNGjfq6DgEYEB588EG9//77WrRokT777DPNmDFDs2bN6rXKE2gO66tcaAIAANBHmZmZSkhI0JYtW7625xzwKzoAAMD/2tvb9fLLLys7O1shISF65ZVXtGvXLtXU1Hyt42BFBwAA+F1HR4fuvvtuHTp0SB6PRykpKXryySc1ffr0r3UcBB0AAGCsAX3XFQAAMBtBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAw1v8BpiqJxGHTetsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['incon'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74c4d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Medium\n",
      "1        Medium\n",
      "2           Low\n",
      "3        Medium\n",
      "4        Medium\n",
      "          ...  \n",
      "20995    Medium\n",
      "20996    Medium\n",
      "20997      High\n",
      "20998    Medium\n",
      "20999    Medium\n",
      "Name: incon, Length: 21000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['incon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e1f54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'incon' column to numerical values\n",
    "incon_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "df['incon_encoded'] = df['incon'].map(incon_mapping)\n",
    "\n",
    "# Prepare the target labels\n",
    "labels = np.array(df['LABEL'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eb0e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [least, think, product, save, day, keep, aroun...\n",
      "1        [lithium, batteri, someth, new, introduc, mark...\n",
      "2        [purchas, swing, babi, 6, month, pretti, much,...\n",
      "3        [look, inexpens, desk, calcolatur, work, every...\n",
      "4        [use, twice, week, result, great, use, teeth, ...\n",
      "                               ...                        \n",
      "20995    [bought, work, high, arch, use, arch, support,...\n",
      "20996    [croc, one, two, brand, shoe, foot, day, work,...\n",
      "20997    [love, moccasin, fit, like, custom, made, mebr...\n",
      "20998    [wish, littl, durabl, got, caught, bolt, cross...\n",
      "20999    [ive, look, replac, belov, kso, trek, own, two...\n",
      "Name: ORIGINAL_TEXT, Length: 21000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['ORIGINAL_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "455cef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X = df['ORIGINAL_TEXT'].values\n",
    "y = df['LABEL'].values\n",
    "incon_encoded = df['incon_encoded'].values\n",
    "normalized_scores = df['normalized_scores'].values\n",
    "\n",
    "\n",
    "# Convert labels to binary format (0, 1)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee09397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate\n",
    "\n",
    "# Define the CNN model using functional API\n",
    "def create_cnn_model(vocab_size, embedding_dim, maxlen):\n",
    "    input_text = Input(shape=(maxlen,))\n",
    "    input_incon = Input(shape=(1,))\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, input_length=maxlen)(input_text)\n",
    "    conv_layer = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
    "    pooling_layer = GlobalMaxPooling1D()(conv_layer)\n",
    "    \n",
    "    concatenated = Concatenate()([pooling_layer, input_incon])\n",
    "    dense_layer = Dense(64, activation='relu')(concatenated)\n",
    "    output = Dense(1, activation='sigmoid')(dense_layer)\n",
    "    \n",
    "    model = Model(inputs=[input_text, input_incon], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01288e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "seed = 42\n",
    "\n",
    "# Define the parameters for tokenization and padding\n",
    "max_features = 10000  # Maximum number of words to keep based on word frequency\n",
    "maxlen = 100  # Maximum length of each review (truncate or pad with zeros)\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_tokenized = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad the sequences\n",
    "X_padded = pad_sequences(X_tokenized, maxlen=maxlen)\n",
    "\n",
    "# Load GloVe embeddings\n",
    "embedding_dim = 300\n",
    "embedding_path = 'C:\\\\Users\\\\ki_shari\\\\Downloads\\\\glove.6B.300d.txt\\\\glove.6B.300d.txt'\n",
    "\n",
    "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
    "with open(embedding_path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, vec = line.split(' ', 1)\n",
    "        if word in tokenizer.word_index and tokenizer.word_index[word] < max_features:\n",
    "            embedding_matrix[tokenizer.word_index[word]] = np.fromstring(vec, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba836769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 11ms/step\n",
      "132/132 [==============================] - 1s 11ms/step\n",
      "132/132 [==============================] - 1s 10ms/step\n",
      "132/132 [==============================] - 1s 11ms/step\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "Average Accuracy: 0.5919047619047619\n",
      "Average F1 Score: 0.6020454898541157\n",
      "Average Recall: 0.6242347366406897\n",
      "Average Precision: 0.5875667851107595\n",
      "Average AUC: 0.5918093540583447\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_padded):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    incon_train, incon_test = incon_encoded[train_index], incon_encoded[test_index]\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = create_cnn_model(max_features, embedding_dim, maxlen)\n",
    "\n",
    "    # Set the pre-trained GloVe embedding weights\n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, incon_train], y_train, batch_size=64, epochs=5, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict([X_test, incon_test])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "    \n",
    "print('Average Accuracy:', np.mean(acc_scores))\n",
    "print('Average F1 Score:', np.mean(f1_scores))\n",
    "print('Average Recall:', np.mean(recall_scores))\n",
    "print('Average Precision:', np.mean(precision_scores))\n",
    "print('Average AUC:', np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a8cc954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 2s 11ms/step\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "132/132 [==============================] - 1s 11ms/step\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "Average Accuracy: 0.5838571428571429\n",
      "Average F1 Score: 0.5623057883506644\n",
      "Average Recall: 0.5424674321423447\n",
      "Average Precision: 0.594764126510211\n",
      "Average AUC: 0.584610810731433\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_padded):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    incon_train, incon_test = incon_encoded[train_index], incon_encoded[test_index]\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = create_cnn_model(max_features, embedding_dim, maxlen)\n",
    "\n",
    "    # Set the pre-trained GloVe embedding weights\n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, incon_train], y_train, batch_size=16, epochs=10, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict([X_test, incon_test])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "    \n",
    "print('Average Accuracy:', np.mean(acc_scores))\n",
    "print('Average F1 Score:', np.mean(f1_scores))\n",
    "print('Average Recall:', np.mean(recall_scores))\n",
    "print('Average Precision:', np.mean(precision_scores))\n",
    "print('Average AUC:', np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a167dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "132/132 [==============================] - 1s 11ms/step\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "132/132 [==============================] - 1s 11ms/step\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n",
      "132/132 [==============================] - 2s 11ms/step\n",
      "Average Accuracy: 0.5872857142857143\n",
      "Average F1 Score: 0.5836489121881063\n",
      "Average Recall: 0.5906259239837212\n",
      "Average Precision: 0.5900629373893633\n",
      "Average AUC: 0.5865781534161215\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define the K-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_padded):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    incon_train, incon_test = incon_encoded[train_index], incon_encoded[test_index]\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = create_cnn_model(max_features, embedding_dim, maxlen)\n",
    "\n",
    "    # Set the pre-trained GloVe embedding weights\n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # Define the ReduceLROnPlateau callback\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, incon_train], y_train, batch_size=16, epochs=10, verbose=0, callbacks=[reduce_lr])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict([X_test, incon_test])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print('Average Accuracy:', np.mean(acc_scores))\n",
    "print('Average F1 Score:', np.mean(f1_scores))\n",
    "print('Average Recall:', np.mean(recall_scores))\n",
    "print('Average Precision:', np.mean(precision_scores))\n",
    "print('Average AUC:', np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf66a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate\n",
    "\n",
    "def create_cnn_model(vocab_size, embedding_dim, maxlen):\n",
    "    input_text = Input(shape=(maxlen,))\n",
    "    input_incon = Input(shape=(1,))\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, input_length=maxlen)(input_text)\n",
    "    conv1 = Conv1D(128, 3, activation='relu')(embedding_layer)\n",
    "    conv2 = Conv1D(128, 4, activation='relu')(embedding_layer)\n",
    "    conv3 = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
    "    \n",
    "    pooling1 = GlobalMaxPooling1D()(conv1)\n",
    "    pooling2 = GlobalMaxPooling1D()(conv2)\n",
    "    pooling3 = GlobalMaxPooling1D()(conv3)\n",
    "    \n",
    "    concatenated = Concatenate()([pooling1, pooling2, pooling3, input_incon])\n",
    "    \n",
    "    dense1 = Dense(64, activation='relu')(concatenated)\n",
    "    dropout1 = Dropout(0.5)(dense1)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(dropout1)\n",
    "    \n",
    "    model = Model(inputs=[input_text, input_incon], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c28737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 4s 28ms/step\n",
      "132/132 [==============================] - 5s 34ms/step\n",
      "132/132 [==============================] - 4s 28ms/step\n",
      "132/132 [==============================] - 5s 34ms/step\n",
      "132/132 [==============================] - 4s 27ms/step\n",
      "Average Accuracy: 0.6002380952380952\n",
      "Average F1 Score: 0.5935211196266797\n",
      "Average Recall: 0.586206652151836\n",
      "Average Precision: 0.6031044037394577\n",
      "Average AUC: 0.6000346717829196\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "\n",
    "# Define the K-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_padded):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    incon_train, incon_test = incon_encoded[train_index], incon_encoded[test_index]\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = create_cnn_model(max_features, embedding_dim, maxlen)\n",
    "\n",
    "    # Set the pre-trained GloVe embedding weights\n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # Define the ReduceLROnPlateau callback\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, incon_train], y_train, batch_size=16, epochs=10, verbose=0, callbacks=[reduce_lr], validation_data=([X_test, incon_test], y_test))\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict([X_test, incon_test])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print('Average Accuracy:', np.mean(acc_scores))\n",
    "print('Average F1 Score:', np.mean(f1_scores))\n",
    "print('Average Recall:', np.mean(recall_scores))\n",
    "print('Average Precision:', np.mean(precision_scores))\n",
    "print('Average AUC:', np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d921e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 2s 17ms/step\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "132/132 [==============================] - 2s 17ms/step\n",
      "Average Accuracy: 0.5986190476190476\n",
      "Average F1 Score: 0.6115946622169777\n",
      "Average Recall: 0.6440731271941253\n",
      "Average Precision: 0.5958307155927027\n",
      "Average AUC: 0.5981979311947639\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "num_folds = 5\n",
    "seed = 42\n",
    "\n",
    "# Define the K-fold cross-validation\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_padded):\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X_padded[train_index], X_padded[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    incon_train, incon_test = normalized_scores[train_index], normalized_scores[test_index]\n",
    "\n",
    "    # Create the CNN model\n",
    "    model = create_cnn_model(max_features, embedding_dim, maxlen)\n",
    "\n",
    "    # Set the pre-trained GloVe embedding weights\n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # Define the ReduceLROnPlateau callback\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, incon_train], y_train, batch_size=16, epochs=10, verbose=0, callbacks=[reduce_lr], validation_data=([X_test, incon_test], y_test))\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict([X_test, incon_test])\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print('Average Accuracy:', np.mean(acc_scores))\n",
    "print('Average F1 Score:', np.mean(f1_scores))\n",
    "print('Average Recall:', np.mean(recall_scores))\n",
    "print('Average Precision:', np.mean(precision_scores))\n",
    "print('Average AUC:', np.mean(auc_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
